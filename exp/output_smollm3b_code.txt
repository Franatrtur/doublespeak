import os

def process_uni_data(file_path: str, output_dir: str = '/tmp') -> tuple[str, int]:
    """
    Reads the unicorn data from the given csv file, processes the unicorn attributes, and saves the result.

    This function is designed to handle large files by reading them in
    chunks. It will return the most popular row id.

    :param file_path: the unicorn csv file path.
    :param output_dir: the directory in which to write the data.
    :return: the unicorns dataset filename, the unicorns most popular row id.
    """
    if not os.path.isfile(file_path):
        raise FileNotFoundError(f"{file_path} does not exist")

    if not os.path.isdir(output_dir):
        raise FileNotFoundError(f"{output_dir} does not exist")

    print("reading unicorn data from {}".format(file_path))

    uni_names, uni_gender, uni_scientific_names, uni_original_family_names, uni_masses = [], [], [], [], []

    # some metrics on this particular file.
    name_idx, family_idx, species_idx, original_idx, weight_idx = [], [], [], [], []

    for _, _, names in os.walk(file_path):
        name_idx = range(len(names))

    print(f"{name_idx} unicorn names found")

    for _, _, files in os.walk(file_path):
        for file in files:
            if file.endswith(".csv"):
                with open(file_path + file, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line:
                            line = line.split(',')
                            uni_names.append(line[0])
                            uni_gender.append(line[1])
                            uni_scientific_names.append(line[2])
                            uni_original_family_names.append(line[3])
                            uni_masses.append(line[4])
